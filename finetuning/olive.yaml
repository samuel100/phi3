# yaml-language-server: $schema=https://microsoft.github.io/Olive/schema.json
input_model:
  type: PyTorchModel
  config:
    hf_config:
      model_name: microsoft/Phi-3-mini-4k-instruct
      task: text-generation
      from_pretrained_args:
        trust_remote_code: true  

data_configs:
  - name: phrase_dataset
    type: HuggingfaceContainer
    load_dataset_config:
      params:
        data_name: json
        data_files: data/phrase_classification_dataset.json
        split: train
    pre_process_data_config:
      params:
        dataset_type: corpus
        text_cols:
          - phrase
          - tone
        text_template: <|user|>\n{phrase}<|end|>\n<|assistant|>\n{tone}<|end|>
        corpus_strategy: join
        source_max_len: 1024
        pad_to_max_len: false
        use_attention_mask: false

passes:
  lora:
    type: LoRA
    config:
      target_modules:
        - o_proj
        - qkv_proj
      lora_r: 64
      lora_alpha: 64
      lora_dropout: 0.1
      train_data_config: phrase_dataset
      eval_dataset_size: 0.3
      training_args:
        seed: 0
        data_seed: 42
        per_device_train_batch_size: 1
        per_device_eval_batch_size: 1
        gradient_accumulation_steps: 4
        gradient_checkpointing: false
        learning_rate: 0.0001
        max_steps: 1000
        evaluation_strategy: steps
        adam_beta2: 0.999
        max_grad_norm: 0.3
        #report_to: wandb
  merge_weights:
    type: MergeAdapterWeights
  model_builder:
    type: ModelBuilder
    config:
      precision: int4

engine:
  host:
    type: AzureML
    config:
      hf_token: true
      accelerators:
        - device: gpu
          execution_providers:
            - CUDAExecutionProvider
      aml_compute: gpu-cluster
      aml_docker_config:
        base_image: mcr.microsoft.com/azureml/curated/acpt-pytorch-1.13-cuda11.7:43
        conda_file_path: ./conda_dependencies.yaml
  target:
    type: LocalSystem
    config:
      accelerators:
        - device: gpu
          execution_providers:
            - CUDAExecutionProvider    
  search_strategy: false
  cache_dir: .olive-cache
  output_dir: models/lora
  packaging_config: 
    type: AzureMLModels
    name: oliveloramodel

azureml_client:
  aml_config_path: ./config.json
  keyvault_name: REPLACE_WITH_KEYVAULT_NAME
